{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2abfcc85",
   "metadata": {},
   "source": [
    "# Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9de1b35",
   "metadata": {},
   "source": [
    "Assume we want to compute $\\vec y =  a\\vec x+b\\vec y$ where $\\vec x$ and $\\vec y$ are vectors and a and b are constants. \n",
    "Furthermore, assume we wish to compute the dot product\n",
    "of $\\vec x$ and $\\vec y$. And finally assume that we want to do this for both small\n",
    "and large vectors, that is we want to eventually write parallel code using for example GPUs.\n",
    "The following tutorial shows how to do exactly that\n",
    "and more using the dg library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45b21e4e",
   "metadata": {
    "scrolled": true,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from input_line_8:2:\n",
      "In file included from ../../include/dg/algorithm.h:8:\n",
      "\u001b[1m../../include/dg/backend/config.h:20:9: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mNOTE: Fast std::fma(a,b,c) not activated! Using a*b+c instead!\n",
      "      [-W#pragma-messages]\u001b[0m\n",
      "#pragma message( \"NOTE: Fast std::fma(a,b,c) not activated! Using a*b+c ...\n",
      "\u001b[0;1;32m        ^\n",
      "\u001b[0mIn file included from input_line_8:2:\n",
      "In file included from ../../include/dg/algorithm.h:11:\n",
      "In file included from ../../include/dg/topology/split_and_join.h:4:\n",
      "In file included from ../../include/dg/backend/blas1_dispatch_shared.h:12:\n",
      "In file included from ../../include/dg/backend/blas1_serial.h:6:\n",
      "In file included from ../../include/dg/backend/exblas/exdot_serial.h:25:\n",
      "In file included from ../../include/dg/backend/exblas/accumulate.h:19:\n",
      "\u001b[1m../../include/dg/backend/exblas/config.h:31:9: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mWARNING: Instruction set below SSE4.1! Deactivating vectorization!\n",
      "      [-W#pragma-messages]\u001b[0m\n",
      "#pragma message(\"WARNING: Instruction set below SSE4.1! Deactivating vec...\n",
      "\u001b[0;1;32m        ^\n",
      "\u001b[0mIn file included from input_line_8:2:\n",
      "In file included from ../../include/dg/algorithm.h:11:\n",
      "In file included from ../../include/dg/topology/split_and_join.h:4:\n",
      "In file included from ../../include/dg/backend/blas1_dispatch_shared.h:12:\n",
      "In file included from ../../include/dg/backend/blas1_serial.h:6:\n",
      "In file included from ../../include/dg/backend/exblas/exdot_serial.h:25:\n",
      "\u001b[1m../../include/dg/backend/exblas/accumulate.h:93:43: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1mshifting a negative signed value is undefined [-Wshift-negative-value]\u001b[0m\n",
      "        carrybit = (s ? 1ll << KRX : -1ll << KRX);\n",
      "\u001b[0;1;32m                                     ~~~~ ^\n",
      "\u001b[0mIn file included from input_line_8:2:\n",
      "In file included from ../../include/dg/algorithm.h:11:\n",
      "In file included from ../../include/dg/topology/split_and_join.h:4:\n",
      "In file included from ../../include/dg/backend/blas1_dispatch_shared.h:12:\n",
      "In file included from ../../include/dg/backend/blas1_serial.h:6:\n",
      "In file included from ../../include/dg/backend/exblas/exdot_serial.h:26:\n",
      "\u001b[1m../../include/dg/backend/exblas/ExSUM.FPE.hpp:143:46: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1munknown attribute 'optimize' ignored [-Wunknown-attributes]\u001b[0m\n",
      "template<typename T, int N, typename TRAITS> UNROLL_ATTRIBUTE\n",
      "\u001b[0;1;32m                                             ^\n",
      "\u001b[0m\u001b[1m../../include/dg/backend/exblas/config.h:42:41: \u001b[0m\u001b[0;1;30mnote: \u001b[0mexpanded from macro 'UNROLL_ATTRIBUTE'\u001b[0m\n",
      "#define UNROLL_ATTRIBUTE __attribute__((optimize(\"unroll-loops\")))\n",
      "\u001b[0;1;32m                                        ^\n",
      "\u001b[0mIn file included from input_line_8:2:\n",
      "In file included from ../../include/dg/algorithm.h:11:\n",
      "In file included from ../../include/dg/topology/split_and_join.h:4:\n",
      "In file included from ../../include/dg/backend/blas1_dispatch_shared.h:12:\n",
      "In file included from ../../include/dg/backend/blas1_serial.h:6:\n",
      "In file included from ../../include/dg/backend/exblas/exdot_serial.h:26:\n",
      "\u001b[1m../../include/dg/backend/exblas/ExSUM.FPE.hpp:189:46: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1munknown attribute 'optimize' ignored [-Wunknown-attributes]\u001b[0m\n",
      "template<typename T, int N, typename TRAITS> UNROLL_ATTRIBUTE\n",
      "\u001b[0;1;32m                                             ^\n",
      "\u001b[0m\u001b[1m../../include/dg/backend/exblas/config.h:42:41: \u001b[0m\u001b[0;1;30mnote: \u001b[0mexpanded from macro 'UNROLL_ATTRIBUTE'\u001b[0m\n",
      "#define UNROLL_ATTRIBUTE __attribute__((optimize(\"unroll-loops\")))\n",
      "\u001b[0;1;32m                                        ^\n",
      "\u001b[0mIn file included from input_line_8:2:\n",
      "In file included from ../../include/dg/algorithm.h:11:\n",
      "In file included from ../../include/dg/topology/split_and_join.h:4:\n",
      "In file included from ../../include/dg/backend/blas1_dispatch_shared.h:12:\n",
      "In file included from ../../include/dg/backend/blas1_serial.h:6:\n",
      "In file included from ../../include/dg/backend/exblas/exdot_serial.h:26:\n",
      "\u001b[1m../../include/dg/backend/exblas/ExSUM.FPE.hpp:221:46: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1munknown attribute 'optimize' ignored [-Wunknown-attributes]\u001b[0m\n",
      "template<typename T, int N, typename TRAITS> UNROLL_ATTRIBUTE\n",
      "\u001b[0;1;32m                                             ^\n",
      "\u001b[0m\u001b[1m../../include/dg/backend/exblas/config.h:42:41: \u001b[0m\u001b[0;1;30mnote: \u001b[0mexpanded from macro 'UNROLL_ATTRIBUTE'\u001b[0m\n",
      "#define UNROLL_ATTRIBUTE __attribute__((optimize(\"unroll-loops\")))\n",
      "\u001b[0;1;32m                                        ^\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#pragma cling add_include_path(\"../../include\")\n",
    "#pragma cling add_include_path(\"../feltor/inc\") // Feltor path\n",
    "#define THRUST_DEVICE_SYSTEM THRUST_DEVICE_SYSTEM_CPP\n",
    "#include <iostream>\n",
    "#include \"dg/algorithm.h\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc4e8c",
   "metadata": {},
   "source": [
    "##  A first example\n",
    "First, we have to include the main feltor library header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b69497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// include the dg-library\n",
    "#include \"dg/algorithm.h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd733ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "double a = 0.5, b = 0.25;\n",
    "std::array<double, 2> x ={2,2}, y = {4,4};\n",
    "// compute a*x+b*y and store it in y\n",
    "dg::blas1::axpby( a, x, b, y);\n",
    "// compute Sum_i x_i y_i\n",
    "double sum = dg::blas1::dot( x,y);\n",
    "// output should be 8\n",
    "std::cout << sum << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b6d2fe",
   "metadata": {},
   "source": [
    "In this code we encounter our first two dg functions, namely `dg::blas1::axpby`\n",
    "and `dg::blas1::dot`. They perform very basic operations, namely adding vectors\n",
    " and computing scalar products respectively. (You can look up their formal documentation [here](https://feltor-dev.github.io/doc/dg/html/group__blas1.html)).\n",
    "The remarkable thing about these two functions is that they are templates.\n",
    "This means you can call them for many different vector classes. We can change the type of `x` and `y`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5079ac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "// works as well\n",
    "std::vector<double> x(2,2), y(2,4);\n",
    "dg::blas1::axpby( a, x, b, y);\n",
    "double sum = dg::blas1::dot( x,y);\n",
    "std::cout << sum << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff54724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "//or\n",
    "thrust::host_vector<double> x(2,2), y(2,4);\n",
    "dg::blas1::axpby( a, x, b, y);\n",
    "double sum = dg::blas1::dot( x,y);\n",
    "std::cout << sum << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c332f1f",
   "metadata": {},
   "source": [
    "All three versions have the same result.\n",
    "    \n",
    "```{note} \n",
    "All of these examples\n",
    "execute on a single CPU thread, that is the compiler chooses the same\n",
    "**serial** implementation of the vector addition and the scalar product.\n",
    "```\n",
    "\n",
    "So let us increase the vector size to say, a Million. Wouldn't it\n",
    "be better to perform these operations in parallel? And a measurement\n",
    "of the execution time would also be nice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c2e4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axpby took 0.913942s\n",
      "Dot   took 0.883924s\n",
      "4e+06\n"
     ]
    }
   ],
   "source": [
    "//use the thrust library to allocate memory on the device\n",
    "thrust::device_vector<double> x(1e6,2), y(1e6,4);\n",
    "//create a Timer\n",
    "dg::Timer t;\n",
    "//start the clock\n",
    "t.tic();\n",
    "dg::blas1::axpby( a, x, b, y);\n",
    "//stop the clock\n",
    "t.toc();\n",
    "std::cout << \"Axpby took \"<<t.diff()<<\"s\\n\";\n",
    "t.tic();\n",
    "double sum = dg::blas1::dot( x,y);\n",
    "t.toc();\n",
    "std::cout << \"Dot   took \"<<t.diff()<<\"s\\n\";\n",
    "//output should be ... large\n",
    "std::cout << sum << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fec1bd",
   "metadata": {},
   "source": [
    "The first thing to notice is that we now use the \n",
    " `thrust::device_vector<double>` class. This is a vector class of\n",
    " the [thrust](https://thrust.github.io/) library, which allocates memory on a GPU.\n",
    " The compiler recognizes that `dg::blas1::axpby` and `dg::blas1::dot`\n",
    " are now called with a GPU vector class and redirects the call to the\n",
    " corresponding CUDA implementation. If you do not have a GPU you can also\n",
    " define the `THRUST_DEVICE_SYSTEM=THRUST_DEVICE_SYSTEM_OMP` Macro, then\n",
    " the call redirects to a OpenMP parallelized version or `THRUST_DEVICE_SYSTEM=THRUST_DEVICE_SYSTEM_CPP` (like it is done in this notebook because xeus-cling does not support OpenMP or cuda very well) then the calls redirect to the serial version again. This is a\n",
    " specialty of the `thrust::device_vector` class of the thrust library\n",
    " that is included in `dg/algorithm.h`.\n",
    "\n",
    " You could also use your own\n",
    " vector class in the `dg::blas1` functions. This is an advanced feature\n",
    " and requires you to provide a specialization of `dg::TensorTraits`\n",
    " for your class, where you specify the parallelization strategy that\n",
    " the libary should choose and how the data is layed out in memory.\n",
    " Please consult the [documentation](https://feltor-dev.github.io/doc/dg/html/index.html#dispatch) for further details on\n",
    "how we dispatch the blas functions\n",
    "and our template traits system.\n",
    "\n",
    "  The `dg::Timer`\n",
    " measures the time it took to execute the functions.\n",
    "\n",
    " So, what if the vector size is even larger `1e8` say? Then an MPI implementation\n",
    " would be handy, wouldn't it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9979a1b7",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The following cell will not exectute because we do not have MPI installed in the notebook. You will need to copy-paste the below code to a file and compile it using the instructions in the quick-start guide.  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135cef03",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "source": [
    "```cpp\n",
    "//activate MPI in FELTOR\n",
    "#include \"mpi.h\" //needs to be included **before** dg/algorithm.h\n",
    "#include \"dg/algorithm.h\"\n",
    "\n",
    "\n",
    "int main(int argc, char* argv[])\n",
    "{\n",
    "    //init MPI\n",
    "    MPI_Init( &argc, &argv);\n",
    "    //let's take all processes\n",
    "    MPI_Comm comm = MPI_COMM_WORLD;\n",
    "    //get the number of MPI processes in the communicator\n",
    "    int np,rank;\n",
    "    MPI_Comm_size(comm, &np);\n",
    "    //get the rank of the calling process\n",
    "    MPI_Comm_rank(comm, &rank);\n",
    "    //allocate and initialize local memory\n",
    "    thrust::device_vector<double> x_local( 1e8/np, 2), y_local(1e8/np, 4);\n",
    "    //combine the local vectors to a global MPI vector\n",
    "    dg::MPI_Vector<thrust::device_vector<double>> x(x_local, comm);\n",
    "    dg::MPI_Vector<thrust::device_vector<double>> y(y_local, comm);\n",
    "\n",
    "    //now repeat the operations from before...\n",
    "    double a = 0.5, b = 0.25;\n",
    "    dg::Timer t;\n",
    "    t.tic();\n",
    "    dg::blas1::axpby( a, x, b, y);\n",
    "    t.toc();\n",
    "    if(rank==0)std::cout << \"Axpby took \"<<t.diff()<<\"s\\n\";\n",
    "    t.tic();\n",
    "    double sum = dg::blas1::dot( x,y);\n",
    "    t.toc();\n",
    "    if(rank==0)std::cout << \"Dot   took \"<<t.diff()<<\"s\\n\";\n",
    "    if(rank==0)std::cout << sum << std::endl;\n",
    "    //be a good MPI citizen and clean up\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8f63a2",
   "metadata": {},
   "source": [
    "```{note}\n",
    "We have just written a hybrid MPI + X code, where X can be either serial, OpenMP or CUDA depending on how the code is compiled!\n",
    "```\n",
    "One remaining thing is that we quickly get tired\n",
    " of writing `thrust::device_vector<double>` and\n",
    "especially `dg::MPI_Vector<thrust::device_vector<double>>`.\n",
    " So we invented convenient typedefs:\n",
    "`\n",
    "dg::DVec x_local( 1e8/np, 2), y_local(1e8/np, 4)\n",
    "dg::x::DVec x(x_local, comm), y(y_local, comm);\n",
    "`\n",
    "\n",
    " which is completely equivalent to the corresponding lines 18 and 20/ 21 above.\n",
    " \n",
    "## Platform independent code\n",
    "\n",
    "The remarkable thing in the above examples is that two lines of code never changed, even if we changed the class of vectors that we use it on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7a684d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "// This is platform independent code\n",
    "dg::blas1::axpby( a, x, b, y);\n",
    "double sum = dg::blas1::dot( x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0045defe",
   "metadata": {},
   "source": [
    "This is a first example of **platform independent code**.\n",
    "It gives us an abstract way to perform vector operations on many different types and with different parallelization. If we implement an algorithm only in terms of `dg::blas1` or similar functions, then \n",
    "this algorithm is **automatically parallelized** for a variety of hardware and works with **many different vector types**.\n",
    "\n",
    "```{note}\n",
    "This is in fact exactly what the dg library does. It provides a set of algorithms all implemented as templates of (at least) the vector class using only the dg::blas1 (and later dg::blas2) functions. We will encounter a first example of such an algorithm in the next chapter of the tutorial: timesteppers.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4b239",
   "metadata": {},
   "source": [
    "## Arbitrarily parallel - The blas1 subroutine\n",
    "One remaining question in this chapter is: what if we do not want to add vectors\n",
    "but multiply them instead? Or take the exponential of each element?\n",
    "There is a selection of predefined `dg::blas1` operations\n",
    "you can choose from for example `dg::blas1::pointwiseDot` or `dg::blas1::scal`. Check out the\n",
    "[documentation](https://feltor-dev.github.io/doc/dg/html/group__blas1.html).\n",
    "\n",
    "If this still does not satisfy your needs, the answer probably is\n",
    "the `dg::blas1::subroutine`.\n",
    "\n",
    "\n",
    " As an example, let us assume that we have two vectors `v` and `w` and we want to compute the elementwise expression $v_i = v_i v_i + a\\sin(w_i)$, where $a$ is a given scalar. The first thing is to write a lambda with our expression and then apply it to all elements in `v` and `w`\n",
    " ```{admonition} Lambdas are amazing\n",
    "Lambda functions will appear continuously throughout this guide, so it is a good idea to at some point refresh your knowledge about them.\n",
    "A good watch on youtube is for example [Lambdas from Scratch - Arthur O'Dwye](https://www.youtube.com/watch?v=3jCOwajNch0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6da39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.05442\n"
     ]
    }
   ],
   "source": [
    "double a = 8.;\n",
    "auto lambda = [&]DG_DEVICE( double& vi, double wi ){\n",
    "                              vi = vi*vi + a*sin(wi);\n",
    "                          };\n",
    "dg::HVec v( 1e6,2), w(1e6,4);\n",
    "dg::blas1::subroutine( lambda, v,w);\n",
    "std::cout << v[0] << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58aeffd",
   "metadata": {},
   "source": [
    "In the above example we have two host vectors `dg::HVec v` and `w`. In a shared\n",
    " memory code these will be declared as `dg::DVec`\n",
    "In an MPI implementation we would simply write `dg::x::DVec` instead of `dg::DVec`.\n",
    "\n",
    "`dg::blas1::subroutine` simply calls the given **custom Functor** (in our case a lambda) for each element in `v` and `w`. There can be an **arbitrary** number of arguments to the subroutine function (in fact there have to be as many as arguments to the functor/lambda).\n",
    "\n",
    "This in fact means that `dg::blas1::subroutine` is able to compute **any** trivially parallel\n",
    "operation with **any** number of inputs and outputs.\n",
    "```{note}\n",
    "If you do not think this is pure magic, stop here and read again :)\n",
    "(On a technical note, this neat behaviour is possible through `C++-11`-style\n",
    "template parameter packs).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8ad12",
   "metadata": {},
   "source": [
    "## A collection of vectors - recursive execution\n",
    "\n",
    "In many practical problems of fluid dynamics we not only want to integrate one variable, `x` say in time, but several. For example we may want to integrate both density $n$ and velocity $v$. Then, the complete\n",
    "set of variables should be tied together in a single entity. \n",
    "In Feltor you do this simply by allocating \"Vectors of vectors\". The underlying engine automatically (and recursively) expands such constructions. \n",
    "Let us see an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f5dce90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "double a = 0.5, b = 0.25;\n",
    "dg::DVec two( 1e3, 2), four( 1e3, 4);\n",
    "std::array<dg::DVec, 2> x = {two,two}, y = {four,four};\n",
    "// compute a*x+b*y and store it in y\n",
    "dg::blas1::axpby( a, x, b, y);\n",
    "// compute Sum_i x_i y_i\n",
    "double sum = dg::blas1::dot( x,y);\n",
    "// output should be large ...\n",
    "std::cout << sum << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71551255",
   "metadata": {},
   "source": [
    "In this example we have an array of two large vectors (that are not filled with too exciting values, but it is just to show that the code still works). It is also possible to have a vector or map of vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a482b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "double a = 0.5, b = 0.25;\n",
    "dg::DVec two( 1e3, 2), four( 1e3, 4);\n",
    "std::vector<dg::DVec> x {2,two}, y{2,four};\n",
    "// compute a*x+b*y and store it in y\n",
    "dg::blas1::axpby( a, x, b, y);\n",
    "// compute Sum_i x_i y_i\n",
    "double sum = dg::blas1::dot( x,y);\n",
    "// output should be large ...\n",
    "std::cout << sum << std::endl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a80839c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "double a = 0.5, b = 0.25;\n",
    "dg::DVec two( 1e3, 2), four( 1e3, 4);\n",
    "std::map<std::string, dg::DVec> x {{ \"density\",two}, {\"velocity\", two}},\n",
    "                                y {{ \"density\",four}, {\"velocity\", four}};\n",
    "// compute a*x+b*y and store it in y\n",
    "dg::blas1::axpby( a, x, b, y);\n",
    "// compute Sum_i x_i y_i\n",
    "double sum = dg::blas1::dot( x,y);\n",
    "// output should be large ...\n",
    "std::cout << sum << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecfaab4",
   "metadata": {},
   "source": [
    "Since the implementation works recursively, the \"innver vector\" can be a recusive vector again that is something like  `std::vector<std::array<dg::DVec,2>>` is also possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f45946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
